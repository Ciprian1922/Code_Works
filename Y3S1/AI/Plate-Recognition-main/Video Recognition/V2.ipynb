{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "import easyocr\n",
    "import os\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def character_recognition(img, location): \n",
    "    if len(location) > 0:\n",
    "        tmp=img[location[0]: location[1], location[2]: location[3] ] #crop the image by given coordinates\n",
    "        image=cv2.cvtColor(tmp, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        reader = easyocr.Reader(['en'], gpu=False)\n",
    "        result = reader.readtext(image)\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete(file):\n",
    "    os.remove('/Users/milovan/Desktop/PlateRecognitionV2' + '/' + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROVIDE PATH TO VIDEO DIRECTORY\n",
    "VIDEO_PATHS = '/Users/milovan/Desktop/PlateRecognitionV2/videoTrain.avi'\n",
    "\n",
    "# PROVIDE PATH TO MODEL DIRECTORY\n",
    "PATH_TO_MODEL_DIR = '/Users/milovan/Desktop/PlateRecognitionV2/my_model'\n",
    "\n",
    "# PROVIDE PATH TO LABEL MAP\n",
    "PATH_TO_LABELS = '/Users/milovan/Desktop/PlateRecognitionV2/label-map.pbtxt'\n",
    "\n",
    "# PROVIDE THE MINIMUM CONFIDENCE THRESHOLD\n",
    "MIN_CONF_THRESH = 0.50\n",
    "\n",
    "# Load the model\n",
    "# ~~~~~~~~~~~~~~\n",
    "import time\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "\n",
    "PATH_TO_SAVED_MODEL = PATH_TO_MODEL_DIR + \"/saved_model\"\n",
    "\n",
    "print('Loading model...', end='')\n",
    "start_time = time.time()\n",
    "\n",
    "# Load saved model and build the detection function\n",
    "detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print('Done! Took {} seconds'.format(elapsed_time))\n",
    "\n",
    "# Load label map data (for plotting)\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,use_display_name=True)\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n",
    "\n",
    "def load_image_into_numpy_array(path):\n",
    "    \"\"\"Load an image from file into a numpy array.\n",
    "    Puts image into numpy array to feed into tensorflow graph.\n",
    "    \"\"\"\n",
    "    return np.array(Image.open(path))\n",
    "\n",
    "print('Running inference for {}... '.format(VIDEO_PATHS), end='')\n",
    "\n",
    "video = cv2.VideoCapture(VIDEO_PATHS)\n",
    "while(video.isOpened()):\n",
    "\n",
    "    # Acquire frame and expand frame dimensions to have shape: [1, None, None, 3]\n",
    "    # i.e. a single-column array, where each item in the column has the pixel RGB value\n",
    "    ret, frame = video.read()\n",
    "    \n",
    "    cv2.imwrite(\"tempFrame.jpg\", frame)\n",
    "    \n",
    "    image = cv2.imread(\"tempFrame.jpg\")\n",
    "    \n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "    frame_expanded = np.expand_dims(frame_rgb, axis=0)\n",
    "    \n",
    "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "    input_tensor = tf.convert_to_tensor(frame)\n",
    "    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
    "    input_tensor = input_tensor[tf.newaxis, ...]\n",
    "\n",
    "    # input_tensor = np.expand_dims(image_np, 0)\n",
    "    detections = detect_fn(input_tensor)\n",
    "\n",
    "    # All outputs are batches tensors.\n",
    "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "    # We're only interested in the first num_detections.\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy() for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "            \n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    frame_with_detections = frame.copy()\n",
    "    \n",
    "    # SET MIN SCORE THRESH TO MINIMUM THRESHOLD FOR DETECTIONS\n",
    "    \n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "          frame_with_detections,\n",
    "          detections['detection_boxes'],\n",
    "          detections['detection_classes'],\n",
    "          detections['detection_scores'],\n",
    "          category_index,\n",
    "          use_normalized_coordinates=True,\n",
    "          max_boxes_to_draw=200,\n",
    "          min_score_thresh=MIN_CONF_THRESH,\n",
    "          agnostic_mode=False)\n",
    "    \n",
    "    boxes = detections['detection_boxes'] \n",
    "    scores = detections['detection_scores']\n",
    "    min_score_tresh = 0.5\n",
    "    bboxes = boxes[scores > min_score_tresh]\n",
    "    width, height = image.shape[:2]\n",
    "    final_box=[]\n",
    "    for box in bboxes:\n",
    "        ymin, xmin, ymax, xmax = box\n",
    "        final_box = [int(ymin * width), int(xmin * height), int(ymax * width), int(xmax *height)]\n",
    "    \n",
    "    location = final_box\n",
    "    \n",
    "    cv2.imshow('Object Detector', frame_with_detections)\n",
    "    \n",
    "    character_recognition(image, location)\n",
    "    \n",
    "    delete('tempFrame.jpg')\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
